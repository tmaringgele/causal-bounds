{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0bb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from binaryIV import simulate_deterministic_data_with_probabilistic_ate, extract_prob_dict, entropy_of_array\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "# from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Train a decision tree classifier to predict 'tightest_bounds'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f428a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_pickle('binaryIV_results.pkl')\n",
    "# Add a new column 'tightest_bounds' to identify the algorithm with the smallest bound width\n",
    "bound_columns = {\n",
    "    'causaloptim': 'causaloptim_bound_width',\n",
    "    '2SLS': '2SLS_CI_width',\n",
    "    'entropyBounds': 'entropyBounds_bound_width',\n",
    "    'autobound': 'autobound_bound_width'\n",
    "}\n",
    "data['tightest_bounds'] = data[\n",
    "    list(bound_columns.values())\n",
    "].idxmin(axis=1).map({v: k for k, v in bound_columns.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba9ac197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='tightest_bounds'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['tightest_bounds'].value_counts().plot(kind='bar', alpha=0.5, color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125ff6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['entropy_Y', 'entropy_X', 'entropy_Z', 'corr_X_Y', 'corr_X_Z', 'corr_Y_Z']\n",
    "X = data[features]\n",
    "y = data['tightest_bounds']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2SLS       0.74      0.80      0.77       108\n",
      "   autobound       0.32      0.37      0.34        57\n",
      " causaloptim       0.74      0.69      0.71       235\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.60      0.62      0.61       400\n",
      "weighted avg       0.68      0.67      0.68       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f24a6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2SLS       0.80      0.83      0.81       108\n",
      "   autobound       0.36      0.16      0.22        57\n",
      " causaloptim       0.76      0.84      0.80       235\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.64      0.61      0.61       400\n",
      "weighted avg       0.71      0.74      0.72       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest classifier to predict 'tightest_bounds'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the random forest classifier\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6194aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the neural network using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42, max_iter=500),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and F1 score\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Best F1 Score:', grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_nn_clf = grid_search.best_estimator_\n",
    "nn_y_pred = best_nn_clf.predict(X_test)\n",
    "print(classification_report(y_test, nn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe07827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2SLS       0.89      0.70      0.79       108\n",
      "   autobound       0.50      0.21      0.30        57\n",
      " causaloptim       0.74      0.91      0.81       235\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.71      0.61      0.63       400\n",
      "weighted avg       0.74      0.76      0.73       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the neural network with the best parameters\n",
    "best_nn_clf = MLPClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=500,\n",
    "    hidden_layer_sizes=(150, 100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_nn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "nn_y_pred = best_nn_clf.predict(X_test)\n",
    "print(classification_report(y_test, nn_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a0832",
   "metadata": {},
   "source": [
    "Idea:\n",
    "* New dataset runs through the classifier\n",
    "* the bounds of the algorithm which the classifier identified as best is automatically returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b91bd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>intercept_X</th>\n",
       "      <th>intercept_Y</th>\n",
       "      <th>b_X_Y</th>\n",
       "      <th>b_Z</th>\n",
       "      <th>b_U_X</th>\n",
       "      <th>b_U_Y</th>\n",
       "      <th>ATE_true</th>\n",
       "      <th>p_Y1</th>\n",
       "      <th>p_Y0</th>\n",
       "      <th>Z</th>\n",
       "      <th>U</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>entropy_Y</th>\n",
       "      <th>entropy_X</th>\n",
       "      <th>entropy_Z</th>\n",
       "      <th>entropy_U</th>\n",
       "      <th>corr_X_Y</th>\n",
       "      <th>corr_X_Z</th>\n",
       "      <th>corr_Y_Z</th>\n",
       "      <th>causaloptim_bound_lower</th>\n",
       "      <th>causaloptim_bound_upper</th>\n",
       "      <th>causaloptim_bound_width</th>\n",
       "      <th>causaloptim_bounds_valid</th>\n",
       "      <th>2SLS_CI_level_percent</th>\n",
       "      <th>2SLS_estimation</th>\n",
       "      <th>2SLS_CI_lower</th>\n",
       "      <th>2SLS_CI_upper</th>\n",
       "      <th>2SLS_CI_width</th>\n",
       "      <th>2SLS_CI_valid</th>\n",
       "      <th>entropyBounds_H(conf)_UB</th>\n",
       "      <th>entropyBounds_bound_lower</th>\n",
       "      <th>entropyBounds_bound_upper</th>\n",
       "      <th>entropyBounds_bound_width</th>\n",
       "      <th>entropyBounds_bounds_valid</th>\n",
       "      <th>autobound_bound_lower</th>\n",
       "      <th>autobound_bound_upper</th>\n",
       "      <th>autobound_bound_width</th>\n",
       "      <th>autobound_bounds_valid</th>\n",
       "      <th>ATE_true_smooth</th>\n",
       "      <th>autobound_bound_lower_smooth</th>\n",
       "      <th>autobound_bound_upper_smooth</th>\n",
       "      <th>tightest_bounds</th>\n",
       "      <th>metalearner_tightest</th>\n",
       "      <th>metalearner_bound_width</th>\n",
       "      <th>metalearner_bounds_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>-0.048032</td>\n",
       "      <td>0.773760</td>\n",
       "      <td>1.621096</td>\n",
       "      <td>-0.649498</td>\n",
       "      <td>[0.032961324273622784, 0.032961324273622784, 0...</td>\n",
       "      <td>[0.8349462801960579, 0.8349462801960579, 0.834...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.610864</td>\n",
       "      <td>0.688909</td>\n",
       "      <td>0.693115</td>\n",
       "      <td>0.693075</td>\n",
       "      <td>-0.656565</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>-0.031424</td>\n",
       "      <td>-0.809524</td>\n",
       "      <td>0.157898</td>\n",
       "      <td>0.967422</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-1.495017</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.758991</td>\n",
       "      <td>0.240991</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.809524</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>0.966206</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>autobound</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.967422</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>749299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.995</td>\n",
       "      <td>-0.933267</td>\n",
       "      <td>-0.364429</td>\n",
       "      <td>0.682056</td>\n",
       "      <td>-0.569919</td>\n",
       "      <td>[0.0067261733291198045, 0.013217026448330598, ...</td>\n",
       "      <td>[0.5, 0.6641973650768443, 0.6641973650768443, ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.657883</td>\n",
       "      <td>0.669634</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>0.692755</td>\n",
       "      <td>-0.570238</td>\n",
       "      <td>-0.232985</td>\n",
       "      <td>0.078573</td>\n",
       "      <td>-0.663114</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.648198</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.333146</td>\n",
       "      <td>-0.710562</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.754833</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.685998</td>\n",
       "      <td>0.313998</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.663114</td>\n",
       "      <td>0.109372</td>\n",
       "      <td>0.772486</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.648198</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.990</td>\n",
       "      <td>1.689792</td>\n",
       "      <td>0.181567</td>\n",
       "      <td>-0.249923</td>\n",
       "      <td>-0.463390</td>\n",
       "      <td>[0.00675966051071325, 0.00675966051071325, 0.0...</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.43784247774382445, 0.5,...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.408578</td>\n",
       "      <td>0.635586</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>-0.564891</td>\n",
       "      <td>0.419036</td>\n",
       "      <td>-0.207080</td>\n",
       "      <td>-0.503649</td>\n",
       "      <td>-0.315985</td>\n",
       "      <td>0.187664</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.366283</td>\n",
       "      <td>-0.519977</td>\n",
       "      <td>-0.212589</td>\n",
       "      <td>0.307388</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.832000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.678990</td>\n",
       "      <td>-0.073715</td>\n",
       "      <td>0.605275</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.187664</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.985</td>\n",
       "      <td>-0.324761</td>\n",
       "      <td>0.327115</td>\n",
       "      <td>-2.582697</td>\n",
       "      <td>-0.279781</td>\n",
       "      <td>[0.0005166144201893448, 0.006793313272604322, ...</td>\n",
       "      <td>[0.07026034714279104, 0.5, 0.5, 0.5, 0.0702603...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.442972</td>\n",
       "      <td>0.692859</td>\n",
       "      <td>0.690833</td>\n",
       "      <td>0.693115</td>\n",
       "      <td>-0.418391</td>\n",
       "      <td>-0.034458</td>\n",
       "      <td>-0.002764</td>\n",
       "      <td>-0.625468</td>\n",
       "      <td>0.295944</td>\n",
       "      <td>0.921413</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.741989</td>\n",
       "      <td>0.257993</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.625468</td>\n",
       "      <td>0.328431</td>\n",
       "      <td>0.953899</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.921413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.980</td>\n",
       "      <td>1.285158</td>\n",
       "      <td>0.598297</td>\n",
       "      <td>1.212007</td>\n",
       "      <td>-0.621645</td>\n",
       "      <td>[0.00682713242213816, 0.00682713242213816, 0.0...</td>\n",
       "      <td>[0.5, 0.5, 0.7706538376815859, 0.7706538376815...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>0.465274</td>\n",
       "      <td>0.583259</td>\n",
       "      <td>0.690553</td>\n",
       "      <td>0.693115</td>\n",
       "      <td>-0.677121</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>-0.191327</td>\n",
       "      <td>-0.823276</td>\n",
       "      <td>-0.150283</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.618801</td>\n",
       "      <td>-0.873916</td>\n",
       "      <td>-0.363686</td>\n",
       "      <td>0.510230</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.851002</td>\n",
       "      <td>0.149001</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.823276</td>\n",
       "      <td>-0.065427</td>\n",
       "      <td>0.757849</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>0.510230</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>426355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.975</td>\n",
       "      <td>0.732277</td>\n",
       "      <td>-0.483578</td>\n",
       "      <td>-0.049504</td>\n",
       "      <td>0.498816</td>\n",
       "      <td>[0.9927931875989926, 0.9931388812295158, 0.993...</td>\n",
       "      <td>[0.4876264335124023, 0.5, 0.5, 0.4876264335124...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>0.531924</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>0.689615</td>\n",
       "      <td>0.691578</td>\n",
       "      <td>0.541701</td>\n",
       "      <td>0.182010</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>-0.044748</td>\n",
       "      <td>0.703443</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.543350</td>\n",
       "      <td>0.144091</td>\n",
       "      <td>0.942609</td>\n",
       "      <td>0.798518</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.240991</td>\n",
       "      <td>0.758990</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.114230</td>\n",
       "      <td>0.703443</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>350222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.980</td>\n",
       "      <td>-0.667406</td>\n",
       "      <td>0.030617</td>\n",
       "      <td>-0.710071</td>\n",
       "      <td>0.569342</td>\n",
       "      <td>[0.9931728675778604, 0.9931728675778604, 0.986...</td>\n",
       "      <td>[0.5, 0.5, 0.32958320704247024, 0.5, 0.3295832...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.642353</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.688139</td>\n",
       "      <td>0.690833</td>\n",
       "      <td>0.574037</td>\n",
       "      <td>-0.233473</td>\n",
       "      <td>-0.119067</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656162</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.496466</td>\n",
       "      <td>0.133529</td>\n",
       "      <td>0.859404</td>\n",
       "      <td>0.725876</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.305998</td>\n",
       "      <td>0.693996</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.104646</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.771313</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.656162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>276977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.985</td>\n",
       "      <td>-0.301349</td>\n",
       "      <td>0.919365</td>\n",
       "      <td>-1.308727</td>\n",
       "      <td>0.637067</td>\n",
       "      <td>[0.9753079748417808, 0.9753079748417808, 0.975...</td>\n",
       "      <td>[0.21269993591781702, 0.21269993591781702, 0.2...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>0.521798</td>\n",
       "      <td>0.661050</td>\n",
       "      <td>0.692859</td>\n",
       "      <td>0.690833</td>\n",
       "      <td>0.638901</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.070939</td>\n",
       "      <td>-0.117572</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.933978</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.081851</td>\n",
       "      <td>-0.496551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.496551</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.194989</td>\n",
       "      <td>0.804990</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.109631</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.926037</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>autobound</td>\n",
       "      <td>causaloptim</td>\n",
       "      <td>0.933978</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>624165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.990</td>\n",
       "      <td>0.795231</td>\n",
       "      <td>0.582216</td>\n",
       "      <td>-1.484354</td>\n",
       "      <td>0.642587</td>\n",
       "      <td>[0.9708479825965327, 0.9708479825965327, 0.993...</td>\n",
       "      <td>[0.18477064078764127, 0.18477064078764127, 0.5...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>0.548764</td>\n",
       "      <td>0.648676</td>\n",
       "      <td>0.692635</td>\n",
       "      <td>0.692947</td>\n",
       "      <td>0.679608</td>\n",
       "      <td>0.216328</td>\n",
       "      <td>0.154158</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.815843</td>\n",
       "      <td>0.768018</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.635420</td>\n",
       "      <td>0.319563</td>\n",
       "      <td>0.951277</td>\n",
       "      <td>0.631714</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.808002</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>0.815843</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>0.631714</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>789436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.995</td>\n",
       "      <td>1.489320</td>\n",
       "      <td>0.401341</td>\n",
       "      <td>0.512597</td>\n",
       "      <td>0.434364</td>\n",
       "      <td>[0.9932738266708788, 0.9932738266708788, 0.995...</td>\n",
       "      <td>[0.5, 0.5, 0.6254151110010939, 0.6254151110010...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.439670</td>\n",
       "      <td>0.610864</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>0.692347</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.228722</td>\n",
       "      <td>0.192493</td>\n",
       "      <td>0.079732</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.729211</td>\n",
       "      <td>True</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.673282</td>\n",
       "      <td>0.375015</td>\n",
       "      <td>0.971550</td>\n",
       "      <td>0.596535</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.158001</td>\n",
       "      <td>0.841994</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>True</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.790090</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>2SLS</td>\n",
       "      <td>0.596535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        seed  intercept_X  intercept_Y  b_X_Y       b_Z     b_U_X     b_U_Y  \\\n",
       "0     226265            0            0 -5.000 -0.048032  0.773760  1.621096   \n",
       "1     749299            0            0 -4.995 -0.933267 -0.364429  0.682056   \n",
       "2      13137            0            0 -4.990  1.689792  0.181567 -0.249923   \n",
       "3      94295            0            0 -4.985 -0.324761  0.327115 -2.582697   \n",
       "4     736973            0            0 -4.980  1.285158  0.598297  1.212007   \n",
       "...      ...          ...          ...    ...       ...       ...       ...   \n",
       "1995  426355            0            0  4.975  0.732277 -0.483578 -0.049504   \n",
       "1996  350222            0            0  4.980 -0.667406  0.030617 -0.710071   \n",
       "1997  276977            0            0  4.985 -0.301349  0.919365 -1.308727   \n",
       "1998  624165            0            0  4.990  0.795231  0.582216 -1.484354   \n",
       "1999  789436            0            0  4.995  1.489320  0.401341  0.512597   \n",
       "\n",
       "      ATE_true                                               p_Y1  \\\n",
       "0    -0.649498  [0.032961324273622784, 0.032961324273622784, 0...   \n",
       "1    -0.569919  [0.0067261733291198045, 0.013217026448330598, ...   \n",
       "2    -0.463390  [0.00675966051071325, 0.00675966051071325, 0.0...   \n",
       "3    -0.279781  [0.0005166144201893448, 0.006793313272604322, ...   \n",
       "4    -0.621645  [0.00682713242213816, 0.00682713242213816, 0.0...   \n",
       "...        ...                                                ...   \n",
       "1995  0.498816  [0.9927931875989926, 0.9931388812295158, 0.993...   \n",
       "1996  0.569342  [0.9931728675778604, 0.9931728675778604, 0.986...   \n",
       "1997  0.637067  [0.9753079748417808, 0.9753079748417808, 0.975...   \n",
       "1998  0.642587  [0.9708479825965327, 0.9708479825965327, 0.993...   \n",
       "1999  0.434364  [0.9932738266708788, 0.9932738266708788, 0.995...   \n",
       "\n",
       "                                                   p_Y0  \\\n",
       "0     [0.8349462801960579, 0.8349462801960579, 0.834...   \n",
       "1     [0.5, 0.6641973650768443, 0.6641973650768443, ...   \n",
       "2     [0.5, 0.5, 0.5, 0.5, 0.43784247774382445, 0.5,...   \n",
       "3     [0.07026034714279104, 0.5, 0.5, 0.5, 0.0702603...   \n",
       "4     [0.5, 0.5, 0.7706538376815859, 0.7706538376815...   \n",
       "...                                                 ...   \n",
       "1995  [0.4876264335124023, 0.5, 0.5, 0.4876264335124...   \n",
       "1996  [0.5, 0.5, 0.32958320704247024, 0.5, 0.3295832...   \n",
       "1997  [0.21269993591781702, 0.21269993591781702, 0.2...   \n",
       "1998  [0.18477064078764127, 0.18477064078764127, 0.5...   \n",
       "1999  [0.5, 0.5, 0.6254151110010939, 0.6254151110010...   \n",
       "\n",
       "                                                      Z  \\\n",
       "0     [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1     [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "2     [0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "3     [1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "4     [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1995  [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, ...   \n",
       "1996  [0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "1997  [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, ...   \n",
       "1998  [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...   \n",
       "1999  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                                      U  \\\n",
       "0     [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, ...   \n",
       "1     [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "2     [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "3     [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "4     [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "1995  [1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...   \n",
       "1996  [0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, ...   \n",
       "1997  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1998  [1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "1999  [0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, ...   \n",
       "\n",
       "                                                      X  \\\n",
       "0     [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "1     [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "2     [0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, ...   \n",
       "3     [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, ...   \n",
       "4     [1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "1995  [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, ...   \n",
       "1996  [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, ...   \n",
       "1997  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...   \n",
       "1998  [1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...   \n",
       "1999  [1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, ...   \n",
       "\n",
       "                                                      Y  entropy_Y  entropy_X  \\\n",
       "0     [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...   0.610864   0.688909   \n",
       "1     [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...   0.657883   0.669634   \n",
       "2     [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   0.408578   0.635586   \n",
       "3     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   0.442972   0.692859   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   0.465274   0.583259   \n",
       "...                                                 ...        ...        ...   \n",
       "1995  [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, ...   0.531924   0.691346   \n",
       "1996  [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...   0.642353   0.667845   \n",
       "1997  [1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...   0.521798   0.661050   \n",
       "1998  [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ...   0.548764   0.648676   \n",
       "1999  [1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   0.439670   0.610864   \n",
       "\n",
       "      entropy_Z  entropy_U  corr_X_Y  corr_X_Z  corr_Y_Z  \\\n",
       "0      0.693115   0.693075 -0.656565  0.019347 -0.031424   \n",
       "1      0.693019   0.692755 -0.570238 -0.232985  0.078573   \n",
       "2      0.693019   0.693019 -0.564891  0.419036 -0.207080   \n",
       "3      0.690833   0.693115 -0.418391 -0.034458 -0.002764   \n",
       "4      0.690553   0.693115 -0.677121  0.265217 -0.191327   \n",
       "...         ...        ...       ...       ...       ...   \n",
       "1995   0.689615   0.691578  0.541701  0.182010  0.118388   \n",
       "1996   0.688139   0.690833  0.574037 -0.233473 -0.119067   \n",
       "1997   0.692859   0.690833  0.638901 -0.055767 -0.070939   \n",
       "1998   0.692635   0.692947  0.679608  0.216328  0.154158   \n",
       "1999   0.693019   0.692347  0.619048  0.228722  0.192493   \n",
       "\n",
       "      causaloptim_bound_lower  causaloptim_bound_upper  \\\n",
       "0                   -0.809524                 0.157898   \n",
       "1                   -0.663114                -0.014916   \n",
       "2                   -0.503649                -0.315985   \n",
       "3                   -0.625468                 0.295944   \n",
       "4                   -0.823276                -0.150283   \n",
       "...                       ...                      ...   \n",
       "1995                -0.044748                 0.703443   \n",
       "1996                 0.010505                 0.666667   \n",
       "1997                -0.117572                 0.816406   \n",
       "1998                 0.047825                 0.815843   \n",
       "1999                 0.079732                 0.808943   \n",
       "\n",
       "      causaloptim_bound_width  causaloptim_bounds_valid  \\\n",
       "0                    0.967422                      True   \n",
       "1                    0.648198                      True   \n",
       "2                    0.187664                      True   \n",
       "3                    0.921413                      True   \n",
       "4                    0.672993                      True   \n",
       "...                       ...                       ...   \n",
       "1995                 0.748191                      True   \n",
       "1996                 0.656162                      True   \n",
       "1997                 0.933978                      True   \n",
       "1998                 0.768018                      True   \n",
       "1999                 0.729211                      True   \n",
       "\n",
       "      2SLS_CI_level_percent  2SLS_estimation  2SLS_CI_lower  2SLS_CI_upper  \\\n",
       "0                      98.0        -1.495017      -1.000000       1.000000   \n",
       "1                      98.0        -0.333146      -0.710562       0.044271   \n",
       "2                      98.0        -0.366283      -0.519977      -0.212589   \n",
       "3                      98.0         0.059125      -1.000000       1.000000   \n",
       "4                      98.0        -0.618801      -0.873916      -0.363686   \n",
       "...                     ...              ...            ...            ...   \n",
       "1995                   98.0         0.543350       0.144091       0.942609   \n",
       "1996                   98.0         0.496466       0.133529       0.859404   \n",
       "1997                   98.0         1.081851      -0.496551       1.000000   \n",
       "1998                   98.0         0.635420       0.319563       0.951277   \n",
       "1999                   98.0         0.673282       0.375015       0.971550   \n",
       "\n",
       "      2SLS_CI_width 2SLS_CI_valid  entropyBounds_H(conf)_UB  \\\n",
       "0          2.000000          True                       1.0   \n",
       "1          0.754833          True                       1.0   \n",
       "2          0.307388          True                       1.0   \n",
       "3          2.000000          True                       1.0   \n",
       "4          0.510230          True                       1.0   \n",
       "...             ...           ...                       ...   \n",
       "1995       0.798518          True                       1.0   \n",
       "1996       0.725876          True                       1.0   \n",
       "1997       1.496551          True                       1.0   \n",
       "1998       0.631714          True                       1.0   \n",
       "1999       0.596535          True                       1.0   \n",
       "\n",
       "      entropyBounds_bound_lower  entropyBounds_bound_upper  \\\n",
       "0                     -0.758991                   0.240991   \n",
       "1                     -0.685998                   0.313998   \n",
       "2                     -0.832000                   0.168000   \n",
       "3                     -0.741989                   0.257993   \n",
       "4                     -0.851002                   0.149001   \n",
       "...                         ...                        ...   \n",
       "1995                  -0.240991                   0.758990   \n",
       "1996                  -0.305998                   0.693996   \n",
       "1997                  -0.194989                   0.804990   \n",
       "1998                  -0.192000                   0.808002   \n",
       "1999                  -0.158001                   0.841994   \n",
       "\n",
       "      entropyBounds_bound_width entropyBounds_bounds_valid  \\\n",
       "0                      0.999983                       True   \n",
       "1                      0.999996                       True   \n",
       "2                      1.000000                       True   \n",
       "3                      0.999982                       True   \n",
       "4                      1.000002                       True   \n",
       "...                         ...                        ...   \n",
       "1995                   0.999981                       True   \n",
       "1996                   0.999994                       True   \n",
       "1997                   0.999979                       True   \n",
       "1998                   1.000001                       True   \n",
       "1999                   0.999995                       True   \n",
       "\n",
       "      autobound_bound_lower  autobound_bound_upper  autobound_bound_width  \\\n",
       "0                 -0.809524               0.156682               0.966206   \n",
       "1                 -0.663114               0.109372               0.772486   \n",
       "2                 -0.678990              -0.073715               0.605275   \n",
       "3                 -0.625468               0.328431               0.953899   \n",
       "4                 -0.823276              -0.065427               0.757849   \n",
       "...                     ...                    ...                    ...   \n",
       "1995              -0.114230               0.703443               0.817674   \n",
       "1996              -0.104646               0.666667               0.771313   \n",
       "1997              -0.109631               0.816406               0.926037   \n",
       "1998               0.022583               0.815843               0.793260   \n",
       "1999               0.018853               0.808943               0.790090   \n",
       "\n",
       "     autobound_bounds_valid  ATE_true_smooth  autobound_bound_lower_smooth  \\\n",
       "0                      True              NaN                           NaN   \n",
       "1                      True              NaN                           NaN   \n",
       "2                      True              NaN                           NaN   \n",
       "3                      True              NaN                           NaN   \n",
       "4                      True              NaN                           NaN   \n",
       "...                     ...              ...                           ...   \n",
       "1995                   True              NaN                           NaN   \n",
       "1996                   True              NaN                           NaN   \n",
       "1997                   True              NaN                           NaN   \n",
       "1998                   True              NaN                           NaN   \n",
       "1999                   True              NaN                           NaN   \n",
       "\n",
       "      autobound_bound_upper_smooth tightest_bounds metalearner_tightest  \\\n",
       "0                              NaN       autobound          causaloptim   \n",
       "1                              NaN     causaloptim          causaloptim   \n",
       "2                              NaN     causaloptim          causaloptim   \n",
       "3                              NaN     causaloptim          causaloptim   \n",
       "4                              NaN            2SLS                 2SLS   \n",
       "...                            ...             ...                  ...   \n",
       "1995                           NaN     causaloptim          causaloptim   \n",
       "1996                           NaN     causaloptim          causaloptim   \n",
       "1997                           NaN       autobound          causaloptim   \n",
       "1998                           NaN            2SLS                 2SLS   \n",
       "1999                           NaN            2SLS                 2SLS   \n",
       "\n",
       "      metalearner_bound_width  metalearner_bounds_valid  \n",
       "0                    0.967422                      True  \n",
       "1                    0.648198                      True  \n",
       "2                    0.187664                      True  \n",
       "3                    0.921413                      True  \n",
       "4                    0.510230                      True  \n",
       "...                       ...                       ...  \n",
       "1995                 0.748191                      True  \n",
       "1996                 0.656162                      True  \n",
       "1997                 0.933978                      True  \n",
       "1998                 0.631714                      True  \n",
       "1999                 0.596535                      True  \n",
       "\n",
       "[2000 rows x 47 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run each datapoint through best_nn_clf and save the result in a new column\n",
    "data['metalearner_tightest'] = best_nn_clf.predict(data[features])\n",
    "\n",
    "# Add a column 'metalearner_bound_width' based on 'metalearner_tightest'\n",
    "data['metalearner_bound_width'] = data.apply(\n",
    "    lambda row: row[bound_columns[row['metalearner_tightest']]], axis=1\n",
    ")\n",
    "\n",
    "# Add a column 'metalearner_bounds_valid' based on 'metalearner_tightest'\n",
    "valid_columns = {\n",
    "    'causaloptim': 'causaloptim_bounds_valid',\n",
    "    '2SLS': '2SLS_CI_valid',\n",
    "    'entropyBounds': 'entropyBounds_bounds_valid',\n",
    "    'autobound': 'autobound_bounds_valid'\n",
    "}\n",
    "data['metalearner_bounds_valid'] = data.apply(\n",
    "    lambda row: row[valid_columns[row['metalearner_tightest']]], axis=1\n",
    ")\n",
    "\n",
    "# Display the first few rows to verify\n",
    "data[['metalearner_tightest', 'metalearner_bound_width', 'metalearner_bounds_valid']].head()\n",
    "\n",
    "### Display mean bound widths and percentage of invalid bounds\n",
    "mean_bounds = data[\n",
    "    ['causaloptim_bound_width', '2SLS_CI_width', 'entropyBounds_bound_width', 'autobound_bound_width', 'metalearner_bound_width']\n",
    "].mean().to_frame(name='Mean Bound Width').T\n",
    "\n",
    "invalid_rates = data[\n",
    "    ['causaloptim_bounds_valid', '2SLS_CI_valid', 'entropyBounds_bounds_valid', 'autobound_bounds_valid', 'metalearner_bounds_valid']\n",
    "].mean().to_frame(name='Invalid Rate').T\n",
    "\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
